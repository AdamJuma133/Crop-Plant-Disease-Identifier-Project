{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7514202,
          "sourceType": "datasetVersion",
          "datasetId": 4376775
        }
      ],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "plant disease research",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamJuma133/Crop-Plant-Disease-Identifier-Project/blob/main/plant_disease_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "jawadali1045_20k_multi_class_crop_disease_images_path = kagglehub.dataset_download('jawadali1045/20k-multi-class-crop-disease-images')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_7GAAbWI-oI",
        "outputId": "1875d3ae-ef53-4661-fd25-07d91f1e13bb"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/jawadali1045/20k-multi-class-crop-disease-images?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.34G/2.34G [00:32<00:00, 78.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-05T07:28:33.034033Z",
          "iopub.execute_input": "2024-09-05T07:28:33.034341Z",
          "iopub.status.idle": "2024-09-05T07:28:38.929023Z",
          "shell.execute_reply.started": "2024-09-05T07:28:33.034308Z",
          "shell.execute_reply": "2024-09-05T07:28:38.928036Z"
        },
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "-QGqE8TYI-oP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required libraries"
      ],
      "metadata": {
        "id": "iV13MBwCI-oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorflow numpy matplotlib keras opencv-python"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T07:28:38.930723Z",
          "iopub.execute_input": "2024-09-05T07:28:38.93115Z",
          "iopub.status.idle": "2024-09-05T07:28:53.255726Z",
          "shell.execute_reply.started": "2024-09-05T07:28:38.931115Z",
          "shell.execute_reply": "2024-09-05T07:28:53.254535Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhgumNo2I-oT",
        "outputId": "017a1d27-f5f2-4593-cb23-3221e6299a94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T07:29:23.625076Z",
          "iopub.execute_input": "2024-09-05T07:29:23.625999Z",
          "iopub.status.idle": "2024-09-05T07:29:36.675147Z",
          "shell.execute_reply.started": "2024-09-05T07:29:23.625952Z",
          "shell.execute_reply": "2024-09-05T07:29:36.674368Z"
        },
        "trusted": true,
        "id": "T-LTcjdDI-oU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA VISUALISATION"
      ],
      "metadata": {
        "id": "tyMJTo4aI-oV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Function to plot 5 images from each folder\n",
        "def plot_images_from_directory(base_directory, title_prefix, images_per_folder=5):\n",
        "    folders = os.listdir(base_directory)\n",
        "\n",
        "    # Iterate over each folder in the base directory\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(base_directory, folder)\n",
        "\n",
        "        if os.path.isdir(folder_path):  # Ensure it's a directory\n",
        "            images = os.listdir(folder_path)[:images_per_folder]  # Get first 'images_per_folder' images\n",
        "\n",
        "            # Plot each image\n",
        "            plt.figure(figsize=(15, 5))  # Adjust the figure size\n",
        "            for i, img_file in enumerate(images):\n",
        "                img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "                try:\n",
        "                    img = Image.open(img_path)  # Load image\n",
        "                    plt.subplot(1, images_per_folder, i+1)  # Create subplots\n",
        "                    plt.imshow(img)\n",
        "                    plt.axis('off')  # Hide axis\n",
        "                    plt.title(f\"{title_prefix}: {folder}\")  # Use folder name as label\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image {img_file}: {e}\")\n",
        "\n",
        "            # Display the images for this folder\n",
        "            plt.show()\n",
        "\n",
        "# Define the base directory path\n",
        "base_directory = '/kaggle/input/20k-multi-class-crop-disease-images/Train/'\n",
        "\n",
        "# Plot 5 images from each folder with the folder name as the label\n",
        "plot_images_from_directory(base_directory, 'Disease')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T07:33:53.96006Z",
          "iopub.execute_input": "2024-09-05T07:33:53.960518Z",
          "iopub.status.idle": "2024-09-05T07:34:46.199853Z",
          "shell.execute_reply.started": "2024-09-05T07:33:53.960478Z",
          "shell.execute_reply": "2024-09-05T07:34:46.198843Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "cIN2Gt7hI-oW",
        "outputId": "2bb02139-a675-437c-9c63-b15f674ce742"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/20k-multi-class-crop-disease-images/Train/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-24c12ac72300>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Plot 5 images from each folder with the folder name as the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mplot_images_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Disease'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-24c12ac72300>\u001b[0m in \u001b[0;36mplot_images_from_directory\u001b[0;34m(base_directory, title_prefix, images_per_folder)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Function to plot 5 images from each folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_images_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_per_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfolders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Iterate over each folder in the base directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/20k-multi-class-crop-disease-images/Train/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA ANALYSIS"
      ],
      "metadata": {
        "id": "XUfOefRXI-oY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to count images in each folder\n",
        "def count_images_in_folders(base_directory):\n",
        "    image_counts = {}\n",
        "\n",
        "    # Iterate over each folder in the base directory\n",
        "    folders = os.listdir(base_directory)\n",
        "\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(base_directory, folder)\n",
        "\n",
        "        if os.path.isdir(folder_path):  # Ensure it's a directory\n",
        "            num_images = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "            image_counts[folder] = num_images\n",
        "\n",
        "    return image_counts\n",
        "\n",
        "# Function to plot the image counts\n",
        "def plot_image_counts(image_counts):\n",
        "    # Sorting the dictionary by values (image count)\n",
        "    sorted_image_counts = dict(sorted(image_counts.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    # Extract folder names and image counts\n",
        "    folders = list(sorted_image_counts.keys())\n",
        "    counts = list(sorted_image_counts.values())\n",
        "\n",
        "    # Plotting the data\n",
        "    plt.figure(figsize=(15, 8))  # Set figure size\n",
        "    plt.barh(folders, counts, color='skyblue')  # Horizontal bar chart\n",
        "    plt.xlabel('Number of Images')\n",
        "    plt.ylabel('Folder Name')\n",
        "    plt.title('Number of Images in Each Folder')\n",
        "    plt.tight_layout()  # Adjust layout\n",
        "    plt.show()\n",
        "\n",
        "# Define the base directory path\n",
        "base_directory = '/kaggle/input/20k-multi-class-crop-disease-images/Train/'\n",
        "\n",
        "# Count images in each folder\n",
        "image_counts = count_images_in_folders(base_directory)\n",
        "\n",
        "# Plot the image counts\n",
        "plot_image_counts(image_counts)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T07:38:10.718653Z",
          "iopub.execute_input": "2024-09-05T07:38:10.718962Z",
          "iopub.status.idle": "2024-09-05T07:38:18.05034Z",
          "shell.execute_reply.started": "2024-09-05T07:38:10.718929Z",
          "shell.execute_reply": "2024-09-05T07:38:18.049379Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "ekG1jk1JI-oZ",
        "outputId": "ecefa7c5-e3b3-4ad3-b2a9-d4415df8433f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/20k-multi-class-crop-disease-images/Train/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-dc52d63772a0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Count images in each folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mimage_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_images_in_folders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Plot the image counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-dc52d63772a0>\u001b[0m in \u001b[0;36mcount_images_in_folders\u001b[0;34m(base_directory)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Iterate over each folder in the base directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mfolders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/20k-multi-class-crop-disease-images/Train/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Model"
      ],
      "metadata": {
        "id": "pEtD-BkOI-oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/kaggle/input/20k-multi-class-crop-disease-images/Train/'\n",
        "#Standardization of data 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T07:40:33.683686Z",
          "iopub.execute_input": "2024-09-05T07:40:33.684603Z",
          "iopub.status.idle": "2024-09-05T07:40:33.689336Z",
          "shell.execute_reply.started": "2024-09-05T07:40:33.684561Z",
          "shell.execute_reply": "2024-09-05T07:40:33.688233Z"
        },
        "trusted": true,
        "id": "ApShUyMAI-ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating training data generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),  # Resizing images to 150x150\n",
        "    batch_size=20,           # Loading 20 images at a time\n",
        "    class_mode='categorical', # Since it's multi-class classification, use 'categorical'\n",
        "    subset='training'         # Set as training data\n",
        ")\n",
        "\n",
        "# Creating validation data generator\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),  # Resizing images to 150x150\n",
        "    batch_size=20,\n",
        "    class_mode='categorical', # Multi-class classification\n",
        "    subset='validation'       # Set as validation data\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T07:46:11.788624Z",
          "iopub.execute_input": "2024-09-05T07:46:11.78911Z",
          "iopub.status.idle": "2024-09-05T07:46:12.552265Z",
          "shell.execute_reply.started": "2024-09-05T07:46:11.789058Z",
          "shell.execute_reply": "2024-09-05T07:46:12.551342Z"
        },
        "trusted": true,
        "id": "XCHBIUo5I-ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class labels for the training data\n",
        "train_class_labels = train_generator.class_indices\n",
        "print(\"Training class labels:\", train_class_labels)\n",
        "\n",
        "# Class labels for the validation data\n",
        "validation_class_labels = validation_generator.class_indices\n",
        "print(\"Validation class labels:\", validation_class_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T07:46:15.877335Z",
          "iopub.execute_input": "2024-09-05T07:46:15.877728Z",
          "iopub.status.idle": "2024-09-05T07:46:15.883345Z",
          "shell.execute_reply.started": "2024-09-05T07:46:15.877692Z",
          "shell.execute_reply": "2024-09-05T07:46:15.882467Z"
        },
        "trusted": true,
        "id": "fyAgH6IOI-oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get class labels for training data\n",
        "train_class_labels = train_generator.class_indices\n",
        "\n",
        "# Get class labels for validation data\n",
        "validation_class_labels = validation_generator.class_indices\n",
        "\n",
        "# Convert class labels to a DataFrame for table-like display\n",
        "train_labels_df = pd.DataFrame(list(train_class_labels.items()), columns=['Class Name', 'Index'])\n",
        "validation_labels_df = pd.DataFrame(list(validation_class_labels.items()), columns=['Class Name', 'Index'])\n",
        "\n",
        "# Display tables\n",
        "print(\"Training Class Labels:\")\n",
        "print(train_labels_df)\n",
        "\n",
        "print(\"\\nValidation Class Labels:\")\n",
        "print(validation_labels_df)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T07:47:29.911662Z",
          "iopub.execute_input": "2024-09-05T07:47:29.912389Z",
          "iopub.status.idle": "2024-09-05T07:47:29.932716Z",
          "shell.execute_reply.started": "2024-09-05T07:47:29.91235Z",
          "shell.execute_reply": "2024-09-05T07:47:29.931739Z"
        },
        "trusted": true,
        "id": "1GvA1NT2I-od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Activation\n",
        "\n",
        "# Define the number of classes\n",
        "n_classes = 42  # Update this to match your number of classes\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and first convolutional block\n",
        "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Second convolutional block\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Third convolutional block\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Fourth convolutional block\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Global Average Pooling\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T07:57:25.612259Z",
          "iopub.execute_input": "2024-09-05T07:57:25.613142Z",
          "iopub.status.idle": "2024-09-05T07:57:27.206567Z",
          "shell.execute_reply.started": "2024-09-05T07:57:25.6131Z",
          "shell.execute_reply": "2024-09-05T07:57:27.205501Z"
        },
        "trusted": true,
        "id": "TyQqwzSeI-od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure train_steps and validation_steps_per_epoch are integers\n",
        "train_steps = int(np.ceil(train_generator.samples / batch_size))\n",
        "validation_steps_per_epoch = int(np.ceil(validation_generator.samples / batch_size))\n",
        "\n",
        "print(\"Train steps:\", train_steps)\n",
        "print(\"Validation steps per epoch:\", validation_steps_per_epoch)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_steps,  # Use calculated train_steps\n",
        "    epochs=10,  # You can adjust the number of epochs as needed\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps_per_epoch  # Use calculated validation_steps\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T08:00:34.911316Z",
          "iopub.execute_input": "2024-09-05T08:00:34.912254Z",
          "iopub.status.idle": "2024-09-05T08:03:54.009941Z",
          "shell.execute_reply.started": "2024-09-05T08:00:34.912199Z",
          "shell.execute_reply": "2024-09-05T08:03:54.008526Z"
        },
        "trusted": true,
        "id": "0iqpF5wPI-oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert ImageDataGenerator to tf.data.Dataset\n",
        "def generator_to_dataset(generator):\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: generator,\n",
        "        output_types=(tf.float32, tf.float32),\n",
        "        output_shapes=([None, 150, 150, 3], [None, len(generator.class_indices)])\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "# Convert train and validation generators\n",
        "train_dataset = generator_to_dataset(train_generator)\n",
        "validation_dataset = generator_to_dataset(validation_generator)\n",
        "\n",
        "# Repeat datasets to ensure enough data for steps\n",
        "train_dataset = train_dataset.repeat()\n",
        "validation_dataset = validation_dataset.repeat()\n",
        "\n",
        "# Batch the datasets\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "validation_dataset = validation_dataset.batch(batch_size)\n",
        "\n",
        "# Calculate steps per epoch\n",
        "train_steps = int(np.ceil(train_generator.samples / batch_size))\n",
        "validation_steps_per_epoch = int(np.ceil(validation_generator.samples / batch_size))\n",
        "\n",
        "print(\"Train steps:\", train_steps)\n",
        "print(\"Validation steps per epoch:\", validation_steps_per_epoch)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=train_steps,  # Use calculated train_steps\n",
        "    epochs=10,  # You can adjust the number of epochs as needed\n",
        "    validation_data=validation_dataset,\n",
        "    validation_steps=validation_steps_per_epoch  # Use calculated validation_steps\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-05T08:07:11.451481Z",
          "iopub.execute_input": "2024-09-05T08:07:11.451908Z",
          "iopub.status.idle": "2024-09-05T08:07:11.61562Z",
          "shell.execute_reply.started": "2024-09-05T08:07:11.451871Z",
          "shell.execute_reply": "2024-09-05T08:07:11.614237Z"
        },
        "trusted": true,
        "id": "rG9YGDLLI-oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# Path to the dataset directory\n",
        "dataset_dir = '/kaggle/input/20k-multi-class-crop-disease-images/Train/'\n",
        "target_count = 200  # Target number of images per class\n",
        "\n",
        "# Create an instance of ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Iterate over each class folder\n",
        "for class_name in os.listdir(dataset_dir):\n",
        "    class_dir = os.path.join(dataset_dir, class_name)\n",
        "\n",
        "    if os.path.isdir(class_dir):\n",
        "        # List all images in the class folder\n",
        "        image_files = [f for f in os.listdir(class_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "        # Check if the number of images is less than the target count\n",
        "        num_images = len(image_files)\n",
        "        if num_images < target_count:\n",
        "            num_images_needed = target_count - num_images\n",
        "\n",
        "            # Create an augmented directory inside the class folder\n",
        "            augmented_class_dir = os.path.join(class_dir, 'augmented')\n",
        "            os.makedirs(augmented_class_dir, exist_ok=True)\n",
        "\n",
        "            # Augment images to reach the target count\n",
        "            for image_file in image_files:\n",
        "                img_path = os.path.join(class_dir, image_file)\n",
        "                img = load_img(img_path)\n",
        "                x = img_to_array(img)\n",
        "                x = np.expand_dims(x, axis=0)\n",
        "\n",
        "                # Generate augmented images\n",
        "                i = 0\n",
        "                for batch in datagen.flow(x, batch_size=1, save_to_dir=augmented_class_dir, save_prefix='aug', save_format='jpeg'):\n",
        "                    i += 1\n",
        "                    if i >= num_images_needed:\n",
        "                        break\n",
        "            print(f\"Augmented {class_name} to {target_count} images.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "cKSChhFuI-of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_v7973LDI-og"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}